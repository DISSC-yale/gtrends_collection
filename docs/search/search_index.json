{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Google Trends Collection Framework","text":"<p>This is in part a simple Python package to handle collection from the Google Trends beta research API, and a minimal framework to organize historical and continuous collection.</p>"},{"location":"#data","title":"Data","text":"<p>A selection of data are collected in the <code>data</code> directory, and are updated weekly.</p> <p>The selection is defined by the files in the <code>scope</code> directory.</p>"},{"location":"#local-use","title":"Local Use","text":"<p>To work with the data locally, you can clone this repository:</p> <pre><code>git clone --depth=1 https://github.com/DISSC-yale/gtrends_collection.git\n</code></pre> <p>Then load the data in Python:</p> <pre><code>from pyarrow.dataset import dataset\n\ndata = dataset(\"gtrends_collection/data\").to_table().to_pandas()\n</code></pre> <p>or R:</p> <pre><code>library(arrow)\n\ndata &lt;- open_dataset(\"gtrends_collection/data\") |&gt; dplyr::collect()\n</code></pre>"},{"location":"#collection","title":"Collection","text":"<p>The <code>scripts/historical_collection.py</code> script is used to collect full histories based on the scope files:</p> <pre><code>python scripts/historical_collection.py\n</code></pre> <p>The <code>scripts/weekly_collection.py</code> script is used by the GitHub Actions workflow to add new data each week.</p>"},{"location":"#authentication","title":"Authentication","text":"<p>A developer key is required to collect from the beta API.</p> <p>This can either be set to the <code>GOOGLE_API_KEY</code> environment variable, or stored in an <code>.env</code> file:</p> <pre><code>GOOGLE_API_KEY=AlphanumericKey\n</code></pre>"},{"location":"Collector/","title":"Collection Mechanism","text":"<p>Collect internet search volumes from the Google Trends timeline for health endpoint.</p> <p>See the schema for more about the API. Only the <code>getTimelinesForHealth</code> endpoint is used here.</p> <p>Parameters:</p> Name Type Description Default <code>scope_dir</code> <code>str</code> <p>Directory containing the <code>terms.txt</code> and <code>locations.txt</code> files. See Specification.</p> <code>'scope'</code> <code>key_dir</code> <code>str</code> <p>Directory containing a <code>.env</code> file, to extract the <code>GOOGLE_API_KEY</code> variable from, if it is not already in the environment.</p> <code>'.'</code> <code>terms_per_batch</code> <code>int</code> <p>Maximum terms to include in each collection batch. Theoretically 30 is the API's max, but more than 1 seems to not work.</p> <code>1</code> <code>wait_time</code> <code>float</code> <p>Seconds to wait between each batch.</p> <code>0.1</code> <code>version</code> <code>str</code> <p>Version of the service API.</p> <code>'v1beta'</code> Specification <p>To process in batches, search terms and locations must be specified in separate files (<code>terms.txt</code> and <code>locations.txt</code>), stored in the <code>scope_dir</code> directory. These should contain 1 term / location code per line.</p> Collection Process <p>Initializing this class retrieves the Google API service, stores the developer key, and points to the scope directory.</p> <p>The <code>process_batches()</code> method reads in the terms and locations, and collects them in batches over the specified time frame.</p> <p>Results from each batch are stored in the <code>batches</code> property, which can be pulled from in case the <code>process_batches</code> process does not complete (such as if the daily rate limit is reached).</p> <p>The <code>collect()</code> method collects a single batch, and can be used on its own.</p> <p>Examples:</p> <pre><code>from gtrends_collection import Collector\n\n# initialize the collector\ncollector = Collector()\n</code></pre> Source code in <code>src\\gtrends_collection\\collector.py</code> <pre><code>class Collector:\n    \"\"\"\n    Collect internet search volumes from the Google Trends timeline for health endpoint.\n\n    See the [schema](https://trends.googleapis.com/$discovery/rest?version=v1beta)\n    for more about the API. Only the `getTimelinesForHealth` endpoint is used here.\n\n    Args:\n        scope_dir (str): Directory containing the `terms.txt` and `locations.txt` files.\n            See Specification.\n        key_dir (str): Directory containing a `.env` file, to extract the\n            `GOOGLE_API_KEY` variable from, if it is not already in the environment.\n        terms_per_batch (int): Maximum terms to include in each collection batch.\n            Theoretically 30 is the API's max, but more than 1 seems to not work.\n        wait_time (float): Seconds to wait between each batch.\n        version (str): Version of the service API.\n\n    Specification:\n        To process in batches, search terms and locations must be specified in separate\n        files (`terms.txt` and `locations.txt`), stored in the `scope_dir` directory.\n        These should contain 1 term / location code per line.\n\n    Collection Process:\n        Initializing this class retrieves the Google API service, stores the\n        developer key, and points to the scope directory.\n\n        The `process_batches()` method reads in the terms and locations,\n        and collects them in batches over the specified time frame.\n\n        Results from each batch are stored in the `batches` property,\n        which can be pulled from in case the `process_batches` process does not complete\n        (such as if the daily rate limit is reached).\n\n        The `collect()` method collects a single batch, and\n        can be used on its own.\n\n    Examples:\n        ```python\n        from gtrends_collection import Collector\n\n        # initialize the collector\n        collector = Collector()\n        ```\n    \"\"\"\n\n    # time to wait between requests\n    _regular_wait_time = 1\n    # time to wait after a `rateLimitExceeded` error\n    _fallback_wait_time = 2\n    batches: ClassVar[List[DataFrame]] = []\n\n    scope_dir = \"scope\"\n    max_terms = 1\n\n    def __init__(self, scope_dir=\"scope\", key_dir=\".\", terms_per_batch=1, wait_time=0.1, version=\"v1beta\"):\n        self._regular_wait_time = wait_time\n        self.scope_dir = scope_dir\n        self.max_terms = terms_per_batch\n\n        key = getenv(\"GOOGLE_API_KEY\")\n        if not key and isfile(f\"{key_dir}/.env\"):\n            with open(f\"{key_dir}/.env\", encoding=\"utf-8\") as content:\n                for pair in content.read().split(\"\\n\"):\n                    name, value = pair.split(\"=\")\n                    if name.startswith(\"GOOGLE_API_KEY\"):\n                        key = value.strip()\n                        break\n        if not key:\n            msg = \"no API key found (GOOGLE_API_KEY environment variable)\"\n            raise RuntimeError(msg)\n\n        self.service = discovery.build(\n            \"trends\",\n            version,\n            discoveryServiceUrl=f\"https://trends.googleapis.com/$discovery/rest?version={version}\",\n            developerKey=key,\n        )\n\n    def process_batches(\n        self,\n        start: Union[str, None] = None,\n        end: Union[str, None] = None,\n        resolution=\"week\",\n        override_terms: Union[List[str], None] = None,\n        override_location: Union[List[str], None] = None,\n    ) -&gt; DataFrame:\n        \"\"\"\n        Processes collection batches from scope.\n\n        Args:\n            start (str | None): First date to collect from; `YYYY-MM-DD`.\n            end (str | None): Last date to collect from; `YYYY-MM-DD`.\n            resolution (str): Collection resolution; `day`, `week`, `month`, or `year`.\n            override_terms (str): List of terms to collect instead of those in scope.\n                Useful for changing collection order or filling out select terms.\n            override_location (str): List of locations to collect from instead of those in scope.\n\n        Examples:\n            ```python\n            # collect across all scope-defined terms and locations in 2024\n            data = collector.process_batches(\"2024-01-01\", \"2024-12-31\")\n            ```\n\n        Returns:\n            A `pandas.DataFrame` of the combined results.\n        \"\"\"\n\n        params: Dict[str, Union[List[str], str]] = {\"timelineResolution\": resolution}\n        if start:\n            params[\"time_startDate\"] = start\n        if end:\n            params[\"time_endDate\"] = end\n\n        if override_terms:\n            terms = override_terms\n        else:\n            with open(f\"{self.scope_dir}/terms.txt\", encoding=\"utf-8\") as content:\n                terms = [term.strip() for term in content.readlines()]\n\n        locations = override_location if override_location else self._get_locations()\n\n        for term_set in range(0, len(terms), self.max_terms):\n            for location in locations:\n                loc = location if len(location) &lt; 9 else location.split(\"-\")[2]\n                batch_params = {\n                    \"terms\": terms[term_set : (term_set + self.max_terms)],\n                    **params,\n                }\n                batch_params[_location_type(loc)] = loc\n                batch = self.collect(loc, batch_params)\n                self.batches.append(batch)\n                sleep(self._regular_wait_time)\n\n        data = concat(self.batches)\n        return data\n\n    def collect(\n        self,\n        location: str,\n        params: Dict[str, Union[List[str], str]],\n    ) -&gt; DataFrame:\n        \"\"\"\n        Collect a single batch.\n\n        Args:\n            location (str): Country (e.g., `US`), region (state; e.g., `US-AL`),\n                or DMA (metro area; e.g., `US-AL-630` or `630`) code.\n            params (dict[str, list[str] | str]): A dictionary with the following entries:\n\n                * `terms` (list[str]): List of terms to collect.\n                * `timelineResolution` (str): Collection resolution; `day`, `week`, `month`, or `year`.\n                * `time_startDate` (str): First date to collect from; `YYYY-MM-DD`.\n                * `time_endDate` (str): First date to collect from; `YYYY-MM-DD`.\n\n        Examples:\n            ```python\n            # collect a small, custom sample\n            data = collector.collect(\n                \"US-NY\",\n                {\n                    \"terms\": [\"cough\", \"/m/01b_21\"],\n                    \"timelineResolution\": \"month\",\n                    \"time_startDate\": \"2014-01-01\",\n                    \"time_endDate\": \"2024-01-01\",\n                },\n            )\n            ```\n\n        Returns:\n            A `pandas.DataFrame` of the prepared results, with these columns:\n\n                * `value`: Number indicating search volume.\n                * `date`: Date the searches were recorded on.\n                * `location`: Location code in which searches were recorded from.\n                * `term`: The search term.\n                * `retrieved`: Date retrived from the API.\n        \"\"\"\n\n        try:\n            # pylint: disable=E1101\n            response = self.service.getTimelinesForHealth(**params).execute()\n        except errors.HttpError as e:\n            if e.reason == \"rateLimitExceeded\":\n                sleep(self._fallback_wait_time)\n                response = self.collect(location, params)\n            else:\n                raise e\n        today = (datetime.datetime.now(datetime.timezone.utc)).strftime(\"%Y-%m-%d\")\n        data = []\n        for line in response[\"lines\"]:\n            points = json_normalize(line[\"points\"])\n            points[\"location\"] = location\n            points[\"term\"] = line[\"term\"]\n            points[\"retrieved\"] = today\n            data.append(points)\n        return concat(data)\n\n    def _get_locations(self) -&gt; List[str]:\n        with open(f\"{self.scope_dir}/locations.txt\", encoding=\"utf-8\") as content:\n            locations = [code.strip() for code in content.readlines()]\n        return locations\n\n    def full_metro_area_codes(self, locations: List[str]) -&gt; List[str]:\n        \"\"\"\n        Adds country and state codes to metro area codes (e.g., `630` becomes `US-AL-630`),\n        based on `scope_dir/locations.txt`.\n\n        Args:\n            locations (List[str]): Locations to potentially prepend full location codes to.\n\n        Examples:\n            ```python\n            collector.full_metro_area_codes([\"630\", \"522\"])\n            ```\n\n        Returns:\n            A version of `locations` with any matching locations expanded.\n        \"\"\"\n        location_map: Dict[str, str] = {}\n        for location in self._get_locations():\n            if len(location) == 9:\n                location_parts = location.split(\"-\")\n                location_map[location_parts[2]] = location\n        return [location_map.get(loc, loc) for loc in locations]\n</code></pre>"},{"location":"Collector/#gtrends_collection.Collector.collect","title":"<code>collect(location, params)</code>","text":"<p>Collect a single batch.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>Country (e.g., <code>US</code>), region (state; e.g., <code>US-AL</code>), or DMA (metro area; e.g., <code>US-AL-630</code> or <code>630</code>) code.</p> required <code>params</code> <code>dict[str, list[str] | str]</code> <p>A dictionary with the following entries:</p> <ul> <li><code>terms</code> (list[str]): List of terms to collect.</li> <li><code>timelineResolution</code> (str): Collection resolution; <code>day</code>, <code>week</code>, <code>month</code>, or <code>year</code>.</li> <li><code>time_startDate</code> (str): First date to collect from; <code>YYYY-MM-DD</code>.</li> <li><code>time_endDate</code> (str): First date to collect from; <code>YYYY-MM-DD</code>.</li> </ul> required <p>Examples:</p> <pre><code># collect a small, custom sample\ndata = collector.collect(\n    \"US-NY\",\n    {\n        \"terms\": [\"cough\", \"/m/01b_21\"],\n        \"timelineResolution\": \"month\",\n        \"time_startDate\": \"2014-01-01\",\n        \"time_endDate\": \"2024-01-01\",\n    },\n)\n</code></pre> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas.DataFrame</code> of the prepared results, with these columns:</p> <ul> <li><code>value</code>: Number indicating search volume.</li> <li><code>date</code>: Date the searches were recorded on.</li> <li><code>location</code>: Location code in which searches were recorded from.</li> <li><code>term</code>: The search term.</li> <li><code>retrieved</code>: Date retrived from the API.</li> </ul> Source code in <code>src\\gtrends_collection\\collector.py</code> <pre><code>def collect(\n    self,\n    location: str,\n    params: Dict[str, Union[List[str], str]],\n) -&gt; DataFrame:\n    \"\"\"\n    Collect a single batch.\n\n    Args:\n        location (str): Country (e.g., `US`), region (state; e.g., `US-AL`),\n            or DMA (metro area; e.g., `US-AL-630` or `630`) code.\n        params (dict[str, list[str] | str]): A dictionary with the following entries:\n\n            * `terms` (list[str]): List of terms to collect.\n            * `timelineResolution` (str): Collection resolution; `day`, `week`, `month`, or `year`.\n            * `time_startDate` (str): First date to collect from; `YYYY-MM-DD`.\n            * `time_endDate` (str): First date to collect from; `YYYY-MM-DD`.\n\n    Examples:\n        ```python\n        # collect a small, custom sample\n        data = collector.collect(\n            \"US-NY\",\n            {\n                \"terms\": [\"cough\", \"/m/01b_21\"],\n                \"timelineResolution\": \"month\",\n                \"time_startDate\": \"2014-01-01\",\n                \"time_endDate\": \"2024-01-01\",\n            },\n        )\n        ```\n\n    Returns:\n        A `pandas.DataFrame` of the prepared results, with these columns:\n\n            * `value`: Number indicating search volume.\n            * `date`: Date the searches were recorded on.\n            * `location`: Location code in which searches were recorded from.\n            * `term`: The search term.\n            * `retrieved`: Date retrived from the API.\n    \"\"\"\n\n    try:\n        # pylint: disable=E1101\n        response = self.service.getTimelinesForHealth(**params).execute()\n    except errors.HttpError as e:\n        if e.reason == \"rateLimitExceeded\":\n            sleep(self._fallback_wait_time)\n            response = self.collect(location, params)\n        else:\n            raise e\n    today = (datetime.datetime.now(datetime.timezone.utc)).strftime(\"%Y-%m-%d\")\n    data = []\n    for line in response[\"lines\"]:\n        points = json_normalize(line[\"points\"])\n        points[\"location\"] = location\n        points[\"term\"] = line[\"term\"]\n        points[\"retrieved\"] = today\n        data.append(points)\n    return concat(data)\n</code></pre>"},{"location":"Collector/#gtrends_collection.Collector.full_metro_area_codes","title":"<code>full_metro_area_codes(locations)</code>","text":"<p>Adds country and state codes to metro area codes (e.g., <code>630</code> becomes <code>US-AL-630</code>), based on <code>scope_dir/locations.txt</code>.</p> <p>Parameters:</p> Name Type Description Default <code>locations</code> <code>List[str]</code> <p>Locations to potentially prepend full location codes to.</p> required <p>Examples:</p> <pre><code>collector.full_metro_area_codes([\"630\", \"522\"])\n</code></pre> <p>Returns:</p> Type Description <code>List[str]</code> <p>A version of <code>locations</code> with any matching locations expanded.</p> Source code in <code>src\\gtrends_collection\\collector.py</code> <pre><code>def full_metro_area_codes(self, locations: List[str]) -&gt; List[str]:\n    \"\"\"\n    Adds country and state codes to metro area codes (e.g., `630` becomes `US-AL-630`),\n    based on `scope_dir/locations.txt`.\n\n    Args:\n        locations (List[str]): Locations to potentially prepend full location codes to.\n\n    Examples:\n        ```python\n        collector.full_metro_area_codes([\"630\", \"522\"])\n        ```\n\n    Returns:\n        A version of `locations` with any matching locations expanded.\n    \"\"\"\n    location_map: Dict[str, str] = {}\n    for location in self._get_locations():\n        if len(location) == 9:\n            location_parts = location.split(\"-\")\n            location_map[location_parts[2]] = location\n    return [location_map.get(loc, loc) for loc in locations]\n</code></pre>"},{"location":"Collector/#gtrends_collection.Collector.process_batches","title":"<code>process_batches(start=None, end=None, resolution='week', override_terms=None, override_location=None)</code>","text":"<p>Processes collection batches from scope.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>str | None</code> <p>First date to collect from; <code>YYYY-MM-DD</code>.</p> <code>None</code> <code>end</code> <code>str | None</code> <p>Last date to collect from; <code>YYYY-MM-DD</code>.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>Collection resolution; <code>day</code>, <code>week</code>, <code>month</code>, or <code>year</code>.</p> <code>'week'</code> <code>override_terms</code> <code>str</code> <p>List of terms to collect instead of those in scope. Useful for changing collection order or filling out select terms.</p> <code>None</code> <code>override_location</code> <code>str</code> <p>List of locations to collect from instead of those in scope.</p> <code>None</code> <p>Examples:</p> <pre><code># collect across all scope-defined terms and locations in 2024\ndata = collector.process_batches(\"2024-01-01\", \"2024-12-31\")\n</code></pre> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A <code>pandas.DataFrame</code> of the combined results.</p> Source code in <code>src\\gtrends_collection\\collector.py</code> <pre><code>def process_batches(\n    self,\n    start: Union[str, None] = None,\n    end: Union[str, None] = None,\n    resolution=\"week\",\n    override_terms: Union[List[str], None] = None,\n    override_location: Union[List[str], None] = None,\n) -&gt; DataFrame:\n    \"\"\"\n    Processes collection batches from scope.\n\n    Args:\n        start (str | None): First date to collect from; `YYYY-MM-DD`.\n        end (str | None): Last date to collect from; `YYYY-MM-DD`.\n        resolution (str): Collection resolution; `day`, `week`, `month`, or `year`.\n        override_terms (str): List of terms to collect instead of those in scope.\n            Useful for changing collection order or filling out select terms.\n        override_location (str): List of locations to collect from instead of those in scope.\n\n    Examples:\n        ```python\n        # collect across all scope-defined terms and locations in 2024\n        data = collector.process_batches(\"2024-01-01\", \"2024-12-31\")\n        ```\n\n    Returns:\n        A `pandas.DataFrame` of the combined results.\n    \"\"\"\n\n    params: Dict[str, Union[List[str], str]] = {\"timelineResolution\": resolution}\n    if start:\n        params[\"time_startDate\"] = start\n    if end:\n        params[\"time_endDate\"] = end\n\n    if override_terms:\n        terms = override_terms\n    else:\n        with open(f\"{self.scope_dir}/terms.txt\", encoding=\"utf-8\") as content:\n            terms = [term.strip() for term in content.readlines()]\n\n    locations = override_location if override_location else self._get_locations()\n\n    for term_set in range(0, len(terms), self.max_terms):\n        for location in locations:\n            loc = location if len(location) &lt; 9 else location.split(\"-\")[2]\n            batch_params = {\n                \"terms\": terms[term_set : (term_set + self.max_terms)],\n                **params,\n            }\n            batch_params[_location_type(loc)] = loc\n            batch = self.collect(loc, batch_params)\n            self.batches.append(batch)\n            sleep(self._regular_wait_time)\n\n    data = concat(self.batches)\n    return data\n</code></pre>"},{"location":"Data/","title":"Data","text":"<p>Summaries of the data collected as of 08:35:02 AM UTC on 2025-03-10</p>"},{"location":"Data/#locations","title":"Locations","text":"<ul> <li>Observations</li> <li>Means</li> </ul>"},{"location":"Data/#dates","title":"Dates","text":"term min max /g/11hy9m64ws Apr 01 2007 Sep 30 2018 /g/11j30ybfx6 Apr 01 2007 Sep 30 2018 /m/0b7k33 Apr 01 2007 Sep 30 2018 /m/0cycc Apr 01 2007 Sep 30 2018 bronchiolitis Apr 01 2007 Sep 30 2018 influenza Apr 01 2007 Sep 30 2018 nirsevimab Apr 01 2007 Sep 30 2018 rsv Apr 01 2007 Sep 30 2018"},{"location":"Data/#values","title":"Values","text":"term min mean std max /g/11hy9m64ws 0.00 80.98 5889.15 4434828.10 /g/11j30ybfx6 0.00 66.17 9456.00 5368845.95 /m/0b7k33 0.00 52.12 4624.37 2077404.38 /m/0cycc 0.00 2477.43 6522.92 1763593.87 bronchiolitis 0.00 50.46 5464.18 2642999.99 influenza 0.00 187.49 3661.87 1362586.92 nirsevimab 0.00 33.83 2763.01 1325261.88 rsv 0.00 278.41 3065.48 1175033.41"},{"location":"Framework/","title":"Framework","text":""},{"location":"Framework/#components","title":"Components","text":"<p>The Framework aspect of this repository consists of the following components:</p> <ol> <li>The <code>GOOGLE_API_KEY</code> environment variable, which may be stored in a <code>.env</code> file.</li> <li>A pair of <code>scope</code> files to define the main collection targets.</li> <li><code>scripts</code> to define different collection tasks.</li> <li>A <code>data</code> output directory to write results to.</li> </ol> <p>These make up a structure around which data are collected. By default, they are assumed to be in the root directory, but each can be redirected with function arguments.</p>"},{"location":"Framework/#automatic-updates","title":"Automatic Updates","text":"<p>On top of those components, the <code>.github/workflows/weekply_collection.yaml</code> file defines a GitHub action used to perform regular updates.</p> <p>This depends on the <code>GOOGLE_API_KEY</code> being defined in actions secretes (Settings &gt; Secrets and variables &gt; ACtions &gt; Secrets) and actions having write permissions (Settings &gt; Actions &gt; General &gt; Workflow permissions).</p>"}]}